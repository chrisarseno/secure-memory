"""
Value Learning System
Implements dynamic value learning and ethical reasoning.
"""

import logging
import time
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class Value:
    """Represents a learned value."""
    name: str
    description: str
    importance: float
    confidence: float
    source: str
    learned_at: datetime

class ValueLearningSystem:
    """
    Value learning system for dynamic ethical reasoning and value evolution.
    """
    
    def __init__(self):
        self.values = {}
        self.value_conflicts = []
        self.learning_efficiency = 84.0
        self.values_evolved = 0
        
        self.initialized = False
        logger.info("Value Learning System initialized")
    
    def initialize(self) -> bool:
        """Initialize the value learning system."""
        try:
            # Initialize with core values
            self._initialize_core_values()
            
            self.initialized = True
            logger.info("âœ… Value Learning System initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize value learning system: {e}")
            return False
    
    def learn_from_experience(self, experience_data: Dict[str, Any]) -> Dict[str, Any]:
        """Learn values from experience."""
        try:
            # Extract potential values from experience
            potential_values = self._extract_values(experience_data)
            
            values_learned = []
            for value_data in potential_values:
                if self._should_learn_value(value_data):
                    value = self._create_value(value_data, experience_data)
                    self.values[value.name] = value
                    values_learned.append(value.name)
                    self.values_evolved += 1
            
            # Check for conflicts
            conflicts = self._check_value_conflicts()
            if conflicts:
                self.value_conflicts.extend(conflicts)
            
            return {
                'values_learned': values_learned,
                'conflicts_detected': len(conflicts),
                'total_values': len(self.values)
            }
            
        except Exception as e:
            logger.error(f"Error learning from experience: {e}")
            return {'error': str(e)}
    
    def get_learning_efficiency(self) -> float:
        """Get learning efficiency score."""
        return self.learning_efficiency
    
    def get_status(self) -> Dict[str, Any]:
        """Get value learning status."""
        conflicts_pending = len([c for c in self.value_conflicts if not c.get('resolved', False)])
        
        return {
            'status': 'active' if self.initialized else 'inactive',
            'load': min(100.0, len(self.values) / 50 * 100),
            'integration': self.learning_efficiency,
            'metadata': {
                'values_evolved': self.values_evolved,
                'conflicts_pending': conflicts_pending,
                'total_values': len(self.values)
            }
        }
    
    def _initialize_core_values(self):
        """Initialize with core human values."""
        core_values = [
            {'name': 'safety', 'description': 'Ensuring safety of humans and systems', 'importance': 1.0},
            {'name': 'honesty', 'description': 'Being truthful and transparent', 'importance': 0.9},
            {'name': 'helpfulness', 'description': 'Providing useful assistance', 'importance': 0.8},
            {'name': 'respect', 'description': 'Respecting human autonomy and dignity', 'importance': 0.9},
            {'name': 'fairness', 'description': 'Treating all individuals fairly', 'importance': 0.8}
        ]
        
        for value_data in core_values:
            value = Value(
                name=value_data['name'],
                description=value_data['description'],
                importance=value_data['importance'],
                confidence=1.0,
                source='initialization',
                learned_at=datetime.now()
            )
            self.values[value.name] = value
    
    def _extract_values(self, experience_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Extract potential values from experience."""
        potential_values = []
        
        # Simple value extraction based on content
        content = experience_data.get('description', '').lower()
        
        if 'privacy' in content:
            potential_values.append({
                'name': 'privacy',
                'description': 'Respecting individual privacy',
                'importance': 0.8
            })
        
        if 'transparency' in content:
            potential_values.append({
                'name': 'transparency',
                'description': 'Being open and transparent',
                'importance': 0.7
            })
        
        return potential_values
    
    def _should_learn_value(self, value_data: Dict[str, Any]) -> bool:
        """Determine if a value should be learned."""
        value_name = value_data.get('name', '')
        
        # Don't learn if we already have this value
        if value_name in self.values:
            return False
        
        # Learn if importance is above threshold
        return value_data.get('importance', 0.0) > 0.5
    
    def _create_value(self, value_data: Dict[str, Any], source_experience: Dict[str, Any]) -> Value:
        """Create a new value."""
        return Value(
            name=value_data['name'],
            description=value_data['description'],
            importance=value_data['importance'],
            confidence=0.6,  # Start with medium confidence
            source=source_experience.get('type', 'experience'),
            learned_at=datetime.now()
        )
    
    def _check_value_conflicts(self) -> List[Dict[str, Any]]:
        """Check for conflicts between values."""
        conflicts = []
        
        # Simple conflict detection
        if 'privacy' in self.values and 'transparency' in self.values:
            privacy_val = self.values['privacy']
            transparency_val = self.values['transparency']
            
            if abs(privacy_val.importance - transparency_val.importance) > 0.3:
                conflicts.append({
                    'type': 'importance_conflict',
                    'values': ['privacy', 'transparency'],
                    'description': 'Privacy and transparency values have conflicting importance levels',
                    'severity': 'medium',
                    'detected_at': datetime.now().isoformat(),
                    'resolved': False
                })
        
        return conflicts
    
    def cleanup(self):
        """Clean up value learning system."""
        logger.info("Value Learning System cleaned up")
